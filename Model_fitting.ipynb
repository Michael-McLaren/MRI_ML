{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aad0698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import importlib.util\n",
    "\n",
    "\n",
    "from tkmodel.TwoCUM import TwoCUMfittingConc\n",
    "from tkmodel.TwoCUM import TwoCUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97d823a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nQuestions for 03/11/2021\\nIs my data generation okay, im worried what kind of random distribution i should use.\\nShould i normalise Fp to between 0 and 1 like the others?\\nPossibly add uncertainty to replicate the test data set a bit more?\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Questions for 03/11/2021\n",
    "Is my data generation okay, im worried what kind of random distribution i should use.\n",
    "Should i normalise Fp to between 0 and 1 like the others?\n",
    "Possibly add uncertainty to replicate the test data set a bit more?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "294b7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful functions\n",
    "\n",
    "def plot_PK(output, true):\n",
    "    AIF_plot = np.load(\"data/AIF.npy\")\n",
    "    t_plot = np.arange(0,366,2.45)\n",
    "    fitted_curve = TwoCUM(output, t_plot, AIF_plot, 0)\n",
    "    plt.plot(t_plot, fitted_curve, label = 'Prediction')\n",
    "    fitted_curve = TwoCUM(true, t_plot, AIF_plot, 0)\n",
    "    plt.plot(t_plot, fitted_curve, label = 'True')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def generate_xy(num_curves):\n",
    "    AIF = np.load(\"data/AIF.npy\")\n",
    "    data_size = AIF.shape[0]\n",
    "    t = np.arange(0,366,2.45)\n",
    "\n",
    "    E = np.random.rand(1,num_curves) #0 to 1 for both E and vp\n",
    "    vp = np.random.rand(1,num_curves)\n",
    "    Fp = 1e-5*np.random.rand(1,num_curves)\n",
    "    \n",
    "#     Fp = abs(np.random.normal(size=num_curves, loc= 1e-5, scale = 1e-4)[None,:])\n",
    "\n",
    "    E_Fp = np.concatenate((E, Fp), axis =0)\n",
    "    y = np.concatenate((E_Fp, vp), axis =0)\n",
    "\n",
    "\n",
    "    x = np.zeros((num_curves, data_size))\n",
    "    for i in range(num_curves):\n",
    "        x[i] = TwoCUM(y[:,i], t, AIF, 0)\n",
    "\n",
    "    y = y.T \n",
    "    \n",
    "    return x,y\n",
    "\n",
    "def training_loop(x, y, epochs, plot = True):\n",
    "    #x is the inputs, y is the true value of the predictions\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "#     loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(y).float()\n",
    "    inputs = Variable(x)\n",
    "    outputs = Variable(y)\n",
    "    torch_dataset = Data.TensorDataset(x, y) #wrapper to join x and y into one dataloader\n",
    "\n",
    "    dataloader = Data.DataLoader(torch_dataset, batch_size=50, shuffle=True) #dataloader for batching and shuffle every epoch\n",
    "\n",
    "    enum = epochs\n",
    "    loss_list = []\n",
    "    for epoch in range(enum):\n",
    "        \n",
    "        for i, (mini_x, mini_y) in enumerate(dataloader): # take out a batch for each step\n",
    "            \n",
    "            \n",
    "            \n",
    "            mini_x = Variable(mini_x)\n",
    "            mini_y = Variable(mini_y)\n",
    "\n",
    "            prediction = net(mini_x)     # input x and predict based on x\n",
    "            loss = loss_fn_batch(prediction, mini_y)\n",
    "            \n",
    "                \n",
    "            optimizer.zero_grad()   # clear gradients so it doesn't stack up over the loops\n",
    "            loss.backward()        # backprop\n",
    "            print(loss.grad)\n",
    "            optimizer.step() \n",
    "            \n",
    "        loss_list.append(loss.detach().numpy())\n",
    "        print(epoch, loss)\n",
    "        if epoch%10 == 0 and plot == True:\n",
    "            #plot one example of prediction vs true values\n",
    "            print('Prediction, True Values')\n",
    "            print(prediction[0].detach().numpy() , mini_y[0].detach().numpy())\n",
    "            plot_PK(prediction[0].detach().numpy(), mini_y[0].detach().numpy())\n",
    "    \n",
    "    #plot the loss over epochs\n",
    "    plt.plot(list(range(enum)), loss_list)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a30c6ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=150, out_features=200, bias=True)\n",
      "  (hidden2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (hidden3): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (hidden4): Linear(in_features=50, out_features=300, bias=True)\n",
      "  (hidden5): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (predict): Linear(in_features=200, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(150, 200)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(200, 100)   # hidden layer\n",
    "        self.hidden3 = torch.nn.Linear(100, 50)\n",
    "        self.hidden4 = torch.nn.Linear(50, 300)\n",
    "        self.hidden5 = torch.nn.Linear(300, 200)\n",
    "        self.predict = torch.nn.Linear(200, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = F.relu(self.hidden4(x))\n",
    "        x = F.relu(self.hidden5(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "    \n",
    "#example custom loss function\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,y_pred, y_true):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss\n",
    "    \n",
    "print(Net())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d794ffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch\n",
      "batch = 2 tensor(0.0039, dtype=torch.float64) torch.Size([])\n",
      "batch = 1 tensor(0.0037, dtype=torch.float64) torch.Size([])\n",
      "batch = 1 second tensor(0.0002, dtype=torch.float64) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "#maybe functions\n",
    "def loss_fn(outputs, targets):\n",
    "    #E, Fp, vp\n",
    "    #time spacings\n",
    "    t = np.arange(0,366,2.45)\n",
    "    AIF = torch.from_numpy(np.load(\"data/AIF.npy\"))\n",
    "\n",
    "    \n",
    "    #For outputs\n",
    "    #First calculate the parameter Tp\n",
    "    E, Fp ,vp = outputs[0], outputs[1], outputs[2]\n",
    "    Tp=(vp/Fp)*(1-E)\n",
    "    #Calculate the IRF\n",
    "    exptTp= torch.exp(-1*t/Tp) #adding dummy variables so it divides properly\n",
    "    R=exptTp*(1-E) + E\n",
    "\n",
    "    #Calculate the convolution\n",
    "    AIF1 = AIF.view(1, 1, -1)\n",
    "    R = torch.flip(R, (0,)).view(1, 1, -1)\n",
    "    temp = t[1]*torch.nn.functional.conv1d(AIF1, R, padding = AIF.shape[0]-1).view(-1)\n",
    "    F_out = Fp*temp[0:len(t)]\n",
    "    \n",
    "    #For targets - copy pasted\n",
    "    E, Fp ,vp = targets[0], targets[1], targets[2]\n",
    "    Tp=(vp/Fp)*(1-E)\n",
    "    #Calculate the IRF\n",
    "    exptTp= torch.exp(-1*t/Tp)\n",
    "    R=exptTp*(1-E) + E\n",
    "    #Calculate the convolution\n",
    "    AIF1 = AIF.view(1, 1, -1)\n",
    "    R = torch.flip(R, (0,)).view(1, 1, -1)\n",
    "    temp = t[1]*torch.nn.functional.conv1d(AIF1, R, padding = AIF.shape[0]-1).view(-1)\n",
    "    F_targets = Fp*temp[0:len(t)]\n",
    "\n",
    "    return torch.sum((F_out - F_targets)**2)/F_out.shape[0]\n",
    "\n",
    "def loss_fn_batch(outputs, targets):\n",
    "    #E, Fp, vp\n",
    "    #time spacings\n",
    "    t = np.arange(0,366,2.45)\n",
    "    t = torch.tensor(t)\n",
    "    \n",
    "    batch_size = outputs[:,0].shape[0]\n",
    "    AIF = torch.from_numpy(np.load(\"data/AIF.npy\"))\n",
    "    AIF1 = AIF.view(1, 1, -1) #reshaped for convolution\n",
    "\n",
    "    \n",
    "    #For outputs\n",
    "    #First calculate the parameter Tp\n",
    "    E, Fp ,vp = outputs[:,0], outputs[:,1], outputs[:,2]\n",
    "    Tp=(vp/Fp)*(1-E)\n",
    "    #Calculate the IRF\n",
    "    exptTp= torch.exp(-1*t[:,None]/Tp[None,:]) #adding dummy variables so it divides properly\n",
    "\n",
    "    R=exptTp*(1-E) + E\n",
    "\n",
    "    #Calculate the convolution\n",
    "    R = torch.flip(R, (0,)).T #Reshape to fit the the convolution\n",
    "    R = torch.unsqueeze(R, 1)\n",
    "    temp = t[1]*torch.nn.functional.conv1d(AIF1, R, padding = AIF.shape[0]-1).view(batch_size, -1)\n",
    "    F_out = Fp.unsqueeze(-1)*temp[:,0:len(t)] #unsqueeze to match dimensions\n",
    "    \n",
    "    #For targets - copy pasted\n",
    "    E_true, Fp_true ,vp_true = targets[:,0], targets[:,1], targets[:,2]\n",
    "    Tp_true=(vp_true/Fp_true)*(1-E_true)\n",
    "    #Calculate the IRF\n",
    "    exptTp_true= torch.exp(-1*t[:,None]/Tp_true[None,:]) #adding dummy variables so it divides properly\n",
    "\n",
    "    R_true=exptTp_true*(1-E_true) + E_true\n",
    "\n",
    "    #Calculate the convolution\n",
    "    R_true = torch.flip(R_true, (0,)).T #Reshape to fit the the convolution\n",
    "    R_true = torch.unsqueeze(R_true, 1)\n",
    "    temp_true = t[1]*torch.nn.functional.conv1d(AIF1, R_true, padding = AIF.shape[0]-1).view(batch_size, -1)\n",
    "    F_targets = Fp_true.unsqueeze(-1)*temp_true[:,0:len(t)] #unsqueeze to match dimensions\n",
    "    \n",
    "    return torch.sum((F_out - F_targets)**2)/F_out.shape[1]\n",
    "\n",
    "\n",
    "outputs, targets = torch.Tensor([[0.5, 2e-4, 0.5],[0.4, 2e-5, 0.3]]), torch.Tensor([[0.2, 2.5e-5, 0.5],[0.1, 6e-5, 0.3]])\n",
    "outputs1, targets1 = torch.Tensor([0.5, 2e-4, 0.5]), torch.Tensor([0.2, 2.5e-5, 0.5])\n",
    "outputs2, targets2 = torch.Tensor([0.4, 2e-5, 0.3]), torch.Tensor([0.1, 6e-5, 0.3])\n",
    "\n",
    "loss1 = loss_fn(outputs1, targets1)\n",
    "loss2 = loss_fn(outputs2, targets2)\n",
    "\n",
    "print('Batch')\n",
    "loss = loss_fn_batch(outputs, targets)\n",
    "print('batch = 2',loss, loss.shape)\n",
    "print('batch = 1',loss1, loss1.shape)\n",
    "print('batch = 1 second',loss2, loss2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# outputs1, targets1 = outputs.detach().numpy(), targets.detach().numpy()\n",
    "# plot_PK(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f9efc044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/v5d7mznx1v39h5mv6nwjnvxm0000gn/T/ipykernel_13202/479595454.py:66: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(loss.grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "0 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Prediction, True Values\n",
      "[nan nan nan] [5.2540523e-01 9.5202631e-06 3.3765993e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/v5d7mznx1v39h5mv6nwjnvxm0000gn/T/ipykernel_13202/479595454.py:66: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(loss.grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "1 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "3 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "4 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "5 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "6 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "7 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "8 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "9 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "10 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Prediction, True Values\n",
      "[nan nan nan] [3.3042848e-01 7.8340263e-06 1.1550818e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/v5d7mznx1v39h5mv6nwjnvxm0000gn/T/ipykernel_13202/479595454.py:66: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(loss.grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "11 tensor(nan, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2m/v5d7mznx1v39h5mv6nwjnvxm0000gn/T/ipykernel_13202/564140184.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2m/v5d7mznx1v39h5mv6nwjnvxm0000gn/T/ipykernel_13202/479595454.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(x, y, epochs, plot)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# clear gradients so it doesn't stack up over the loops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, y = generate_xy(10000)\n",
    "net = Net()\n",
    "\n",
    "training_loop(x ,y ,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0357a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
