{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d716fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "\n",
    "import importlib.util\n",
    "\n",
    "\n",
    "from tkmodel.TwoCUM import TwoCUMfittingConc\n",
    "from tkmodel.TwoCUM import TwoCUM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab178f3a",
   "metadata": {},
   "source": [
    "## Single Batch and Multiple Batch torch version of TwoCUM model\n",
    "\n",
    "#### Input true and predicted PK parameters, it then plots the curves and outputs the MSE loss of the 150 datapoints in each curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac47a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwoCUM_torch(E, Fp ,vp, AIF , t):\n",
    "    Tp=(vp/Fp)*(1-E)\n",
    "    #Calculate the IRF\n",
    "    exptTp= torch.exp(-1*t/Tp) #adding dummy variables so it divides properly\n",
    "    R=exptTp*(1-E) + E\n",
    "\n",
    "    #Calculate the convolution\n",
    "    AIF1 = AIF.view(1, 1, -1)\n",
    "    R = torch.flip(R, (0,)).view(1, 1, -1)\n",
    "    temp = t[1]*torch.nn.functional.conv1d(AIF1, R, padding = AIF.shape[0]-1).view(-1)\n",
    "    F = Fp*temp[0:len(t)]\n",
    "    return F\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    #E, Fp, vp\n",
    "    #time spacings\n",
    "    t = np.arange(0,366,2.45)\n",
    "    AIF = torch.from_numpy(np.load(\"data/AIF.npy\"))\n",
    "\n",
    "    \n",
    "    #For outputs\n",
    "    #First calculate the parameter Tp\n",
    "    E, Fp ,vp = outputs[0], outputs[1], outputs[2]\n",
    "    F_out = TwoCUM_torch(E, Fp ,vp, AIF, t)\n",
    "\n",
    "    \n",
    "    #For targets - copy pasted\n",
    "    E, Fp ,vp = targets[0], targets[1], targets[2]\n",
    "    F_targets = TwoCUM_torch(E, Fp ,vp, AIF, t)\n",
    "\n",
    "    return torch.sum((F_out - F_targets)**2)/F_out.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9fc1944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwoCUM_batch(E, Fp ,vp, AIF1 , t): \n",
    "    batch_size = E.shape[0]\n",
    "    \n",
    "    Tp=(vp/Fp)*(1-E)\n",
    "    #Calculate the IRF\n",
    "    exptTp= torch.exp(-1*t[:,None]/Tp[None,:]) #adding dummy variables so it divides properly\n",
    "\n",
    "    R=exptTp*(1-E) + E\n",
    "\n",
    "    #Calculate the convolution\n",
    "    R = torch.flip(R, (0,)).T #Reshape to fit the the convolution\n",
    "    R = torch.unsqueeze(R, 1)\n",
    "    temp = t[1]*torch.nn.functional.conv1d(AIF1, R, padding = AIF1.shape[2]-1).view(batch_size, -1)\n",
    "    F = Fp.unsqueeze(-1)*temp[:,0:len(t)] #unsqueeze to match dimensions\n",
    "    return F\n",
    "\n",
    "def loss_fn_batch(outputs, targets):\n",
    "    #E, Fp, vp\n",
    "    #time spacings\n",
    "    t = np.arange(0,366,2.45)\n",
    "    t = torch.tensor(t)\n",
    "    \n",
    "    batch_size = outputs[:,0].shape[0]\n",
    "    AIF = torch.from_numpy(np.load(\"data/AIF.npy\"))\n",
    "    AIF1 = AIF.view(1, 1, -1) #reshaped for convolution\n",
    "\n",
    "    \n",
    "    #For outputs\n",
    "    #First calculate the parameter Tp\n",
    "    E, Fp ,vp = outputs[:,0], outputs[:,1], outputs[:,2]\n",
    "    F_out = TwoCUM_batch(E, Fp ,vp, AIF1, t)\n",
    "\n",
    "    \n",
    "    #For targets - copy pasted\n",
    "    E_true, Fp_true ,vp_true = targets[:,0], targets[:,1], targets[:,2]\n",
    "    F_targets = TwoCUM_batch(E_true, Fp_true ,vp_true, AIF1, t)\n",
    "\n",
    "    \n",
    "    MSE = torch.sum((F_out - F_targets)**2)/F_out.shape[1]\n",
    "    return MSE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b5a3baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch\n",
      "batch = 2 tensor(0.0039, dtype=torch.float64) torch.Size([])\n",
      "batch = 1 tensor(0.0037, dtype=torch.float64) torch.Size([])\n",
      "batch = 1 second tensor(0.0002, dtype=torch.float64) torch.Size([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Testing to see if the batch version works just like the single version. \n",
    "\n",
    "As you can see the combined loss of the batch version is the sum of the singles version \n",
    "on the same values.\n",
    "'''\n",
    "outputs, targets = torch.Tensor([[0.5, 2e-4, 0.5],[0.4, 2e-5, 0.3]]), torch.Tensor([[0.2, 2.5e-5, 0.5],[0.1, 6e-5, 0.3]])\n",
    "outputs1, targets1 = torch.Tensor([0.5, 2e-4, 0.5]), torch.Tensor([0.2, 2.5e-5, 0.5])\n",
    "outputs2, targets2 = torch.Tensor([0.4, 2e-5, 0.3]), torch.Tensor([0.1, 6e-5, 0.3])\n",
    "\n",
    "loss1 = loss_fn(outputs1, targets1)\n",
    "loss2 = loss_fn(outputs2, targets2)\n",
    "\n",
    "print('Batch')\n",
    "loss = loss_fn_batch(outputs, targets)\n",
    "print('batch = 2',loss, loss.shape)\n",
    "print('batch = 1',loss1, loss1.shape)\n",
    "print('batch = 1 second',loss2, loss2.shape)\n",
    "\n",
    "outputs, targets = torch.DoubleTensor([[0.5, 2e-4, 0.5],[0.4, 2e-5, 0.3]]), torch.DoubleTensor([[0.2, 2.5e-5, 0.5],[0.1, 6e-5, 0.3]])\n",
    "outputs.requires_grad = True\n",
    "targets.requires_grad = True\n",
    "\n",
    "torch.autograd.gradcheck(loss_fn_batch, (outputs, targets))\n",
    "\n",
    "# outputs1, targets1 = outputs.detach().numpy(), targets.detach().numpy()\n",
    "# plot_PK(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5238bdc",
   "metadata": {},
   "source": [
    "## Clean version to mess with and test the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e297d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE tensor(1., dtype=torch.float64)\n",
      "F_targets tensor([[-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0.],\n",
      "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
      "         -0., -0., -0., -0., -0., -0.]], dtype=torch.float64)\n",
      "F_out tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
      "E tensor([0., 0.], dtype=torch.float64)\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/v5d7mznx1v39h5mv6nwjnvxm0000gn/T/ipykernel_95278/2555747494.py:58: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(loss.grad)\n"
     ]
    }
   ],
   "source": [
    "def TwoCUM_batch_test(E, Fp ,vp, AIF1 , t): \n",
    "\n",
    "    batch_size = E.shape[0]\n",
    "    \n",
    "    Tp=(vp/Fp)*(1-E)\n",
    "    #Calculate the IRF\n",
    "    exptTp= torch.exp(-1*t[:,None]/Tp[None,:]) #adding dummy variables so it divides properly\n",
    "\n",
    "    R=exptTp*(1-E) + E\n",
    "\n",
    "    #Calculate the convolution\n",
    "    R = torch.flip(R, (0,)).T #Reshape to fit the the convolution\n",
    "    R = torch.unsqueeze(R, 1)\n",
    "    temp = t[1]*torch.nn.functional.conv1d(AIF1, R, padding = AIF1.shape[2]-1).view(batch_size, -1)\n",
    "    F = Fp.unsqueeze(-1)*temp[:,0:len(t)] #unsqueeze to match dimensions\n",
    "    return F\n",
    "\n",
    "def loss_fn_batch_test(outputs, targets):\n",
    "    #E, Fp, vp\n",
    "    #time spacings\n",
    "    t = np.arange(0,366,2.45)\n",
    "    t = torch.tensor(t)\n",
    "    \n",
    "    batch_size = outputs[:,0].shape[0]\n",
    "    AIF = torch.from_numpy(np.load(\"data/AIF.npy\"))\n",
    "    AIF1 = AIF.view(1, 1, -1) #reshaped for convolution\n",
    "\n",
    "    \n",
    "    #For outputs\n",
    "    #First calculate the parameter Tp\n",
    "    E, Fp ,vp = outputs[:,0], outputs[:,1], outputs[:,2]\n",
    "    E.register_hook(lambda x: print('E', x))\n",
    "\n",
    "    F_out = TwoCUM_batch_test(E, Fp ,vp, AIF1 , t)\n",
    "    \n",
    "    #For targets - copy pasted\n",
    "    E_true, Fp_true ,vp_true = targets[:,0], targets[:,1], targets[:,2]\n",
    "    F_targets = TwoCUM_batch_test(E, Fp ,vp, AIF1 , t)\n",
    "    \n",
    "    MSE = torch.sum((F_out - F_targets)**2)/F_out.shape[1]\n",
    "    \n",
    "    F_targets.register_hook(lambda x: print('F_targets', x))\n",
    "    F_out.register_hook(lambda x: print('F_out',x))\n",
    "    MSE.register_hook(lambda x: print('MSE',x))\n",
    "\n",
    "\n",
    "    return MSE\n",
    "\n",
    "\n",
    "outputs, targets = torch.DoubleTensor([[0.5, 2e-4, 0.5],[0.4, 2e-5, 0.3]]), torch.DoubleTensor([[0.2, 2.5e-5, 0.5],[0.1, 6e-5, 0.3]])\n",
    "outputs.requires_grad = True\n",
    "targets.requires_grad = True\n",
    "\n",
    "loss = loss_fn_batch_test(outputs, targets)\n",
    "loss.backward()\n",
    "\n",
    "#this always outputs None?\n",
    "print(loss.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9da9a5",
   "metadata": {},
   "source": [
    "# Unchanged version that outputs non-zero grads for at least some stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae92779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE tensor(1., dtype=torch.float64) \n",
      "\n",
      "F_targets tensor([[ 6.1253e-07,  8.8254e-07,  1.1523e-06,  3.7805e-07,  8.1961e-07,\n",
      "         -3.0827e-07, -5.5562e-07,  7.3240e-07,  6.5745e-07,  5.9639e-08,\n",
      "         -1.8812e-07, -7.8499e-07,  1.6730e-07,  4.3780e-07,  5.3597e-07,\n",
      "          8.0607e-07, -4.6309e-06, -3.7176e-05, -7.8609e-05, -1.1536e-04,\n",
      "         -1.4412e-04, -1.6108e-04, -1.7271e-04, -1.8320e-04, -1.9193e-04,\n",
      "         -2.0708e-04, -2.2246e-04, -2.3471e-04, -2.4982e-04, -2.5956e-04,\n",
      "         -2.7318e-04, -2.8751e-04, -2.9765e-04, -3.1220e-04, -3.2366e-04,\n",
      "         -3.3627e-04, -3.4886e-04, -3.5938e-04, -3.7242e-04, -3.8292e-04,\n",
      "         -3.9570e-04, -4.0639e-04, -4.1962e-04, -4.3051e-04, -4.3855e-04,\n",
      "         -4.5080e-04, -4.6280e-04, -4.7276e-04, -4.8520e-04, -4.9717e-04,\n",
      "         -5.0514e-04, -5.1755e-04, -5.2949e-04, -5.4164e-04, -5.5042e-04,\n",
      "         -5.6209e-04, -5.7193e-04, -5.8267e-04, -5.9272e-04, -6.0320e-04,\n",
      "         -6.1436e-04, -6.2371e-04, -6.3439e-04, -6.4416e-04, -6.5415e-04,\n",
      "         -6.6346e-04, -6.7432e-04, -6.8253e-04, -6.9203e-04, -7.0152e-04,\n",
      "         -7.1078e-04, -7.2048e-04, -7.3151e-04, -7.3987e-04, -7.4998e-04,\n",
      "         -7.5941e-04, -7.6689e-04, -7.7416e-04, -7.8491e-04, -7.9565e-04,\n",
      "         -8.0330e-04, -8.1312e-04, -8.2271e-04, -8.3296e-04, -8.3974e-04,\n",
      "         -8.4997e-04, -8.5864e-04, -8.6931e-04, -8.7906e-04, -8.8706e-04,\n",
      "         -8.9420e-04, -9.0349e-04, -9.1040e-04, -9.1967e-04, -9.2893e-04,\n",
      "         -9.3603e-04, -9.4376e-04, -9.5234e-04, -9.6005e-04, -9.6839e-04,\n",
      "         -9.7652e-04, -9.8594e-04, -9.9492e-04, -1.0026e-03, -1.0115e-03,\n",
      "         -1.0186e-03, -1.0264e-03, -1.0316e-03, -1.0382e-03, -1.0429e-03,\n",
      "         -1.0509e-03, -1.0601e-03, -1.0666e-03, -1.0740e-03, -1.0820e-03,\n",
      "         -1.0886e-03, -1.0957e-03, -1.1033e-03, -1.1092e-03, -1.1155e-03,\n",
      "         -1.1218e-03, -1.1287e-03, -1.1346e-03, -1.1410e-03, -1.1490e-03,\n",
      "         -1.1534e-03, -1.1605e-03, -1.1674e-03, -1.1728e-03, -1.1784e-03,\n",
      "         -1.1857e-03, -1.1926e-03, -1.2003e-03, -1.2059e-03, -1.2105e-03,\n",
      "         -1.2160e-03, -1.2206e-03, -1.2264e-03, -1.2324e-03, -1.2396e-03,\n",
      "         -1.2462e-03, -1.2526e-03, -1.2556e-03, -1.2603e-03, -1.2631e-03,\n",
      "         -1.2670e-03, -1.2710e-03, -1.2784e-03, -1.2841e-03, -1.2913e-03],\n",
      "        [-1.4001e-07, -2.0179e-07, -2.6353e-07, -8.6682e-08, -1.8765e-07,\n",
      "          7.0069e-08,  1.2664e-07, -1.6771e-07, -1.5065e-07, -1.4073e-08,\n",
      "          4.2552e-08,  1.7900e-07, -3.8583e-08, -1.0043e-07, -1.2291e-07,\n",
      "         -1.8470e-07,  1.0579e-06,  8.4973e-06,  1.7971e-05,  2.6380e-05,\n",
      "          3.2966e-05,  3.6857e-05,  3.9531e-05,  4.1946e-05,  4.3960e-05,\n",
      "          4.7443e-05,  5.0980e-05,  5.3802e-05,  5.7278e-05,  5.9530e-05,\n",
      "          6.2670e-05,  6.5972e-05,  6.8319e-05,  7.1674e-05,  7.4325e-05,\n",
      "          7.7239e-05,  8.0151e-05,  8.2590e-05,  8.5606e-05,  8.8041e-05,\n",
      "          9.1000e-05,  9.3483e-05,  9.6546e-05,  9.9077e-05,  1.0096e-04,\n",
      "          1.0380e-04,  1.0659e-04,  1.0891e-04,  1.1180e-04,  1.1458e-04,\n",
      "          1.1645e-04,  1.1934e-04,  1.2211e-04,  1.2494e-04,  1.2700e-04,\n",
      "          1.2972e-04,  1.3203e-04,  1.3453e-04,  1.3689e-04,  1.3934e-04,\n",
      "          1.4195e-04,  1.4414e-04,  1.4664e-04,  1.4894e-04,  1.5128e-04,\n",
      "          1.5347e-04,  1.5601e-04,  1.5795e-04,  1.6019e-04,  1.6242e-04,\n",
      "          1.6461e-04,  1.6689e-04,  1.6948e-04,  1.7146e-04,  1.7384e-04,\n",
      "          1.7606e-04,  1.7784e-04,  1.7957e-04,  1.8210e-04,  1.8463e-04,\n",
      "          1.8645e-04,  1.8877e-04,  1.9104e-04,  1.9345e-04,  1.9508e-04,\n",
      "          1.9749e-04,  1.9955e-04,  2.0207e-04,  2.0438e-04,  2.0628e-04,\n",
      "          2.0800e-04,  2.1020e-04,  2.1186e-04,  2.1406e-04,  2.1626e-04,\n",
      "          2.1797e-04,  2.1982e-04,  2.2186e-04,  2.2371e-04,  2.2570e-04,\n",
      "          2.2764e-04,  2.2988e-04,  2.3202e-04,  2.3386e-04,  2.3600e-04,\n",
      "          2.3769e-04,  2.3958e-04,  2.4085e-04,  2.4244e-04,  2.4361e-04,\n",
      "          2.4554e-04,  2.4772e-04,  2.4931e-04,  2.5109e-04,  2.5302e-04,\n",
      "          2.5460e-04,  2.5633e-04,  2.5816e-04,  2.5960e-04,  2.6113e-04,\n",
      "          2.6267e-04,  2.6434e-04,  2.6578e-04,  2.6735e-04,  2.6927e-04,\n",
      "          2.7038e-04,  2.7210e-04,  2.7377e-04,  2.7511e-04,  2.7649e-04,\n",
      "          2.7825e-04,  2.7992e-04,  2.8177e-04,  2.8315e-04,  2.8430e-04,\n",
      "          2.8568e-04,  2.8682e-04,  2.8824e-04,  2.8971e-04,  2.9147e-04,\n",
      "          2.9307e-04,  2.9463e-04,  2.9542e-04,  2.9660e-04,  2.9734e-04,\n",
      "          2.9834e-04,  2.9934e-04,  3.0114e-04,  3.0255e-04,  3.0429e-04]],\n",
      "       dtype=torch.float64) \n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2m/v5d7mznx1v39h5mv6nwjnvxm0000gn/T/ipykernel_95278/1927246720.py:55: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(loss.grad)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def loss_fn_batch_test1(outputs, targets):\n",
    "    #E, Fp, vp\n",
    "    #time spacings\n",
    "    t = np.arange(0,366,2.45)\n",
    "    t = torch.tensor(t)\n",
    "    \n",
    "    batch_size = outputs[:,0].shape[0]\n",
    "    AIF = torch.from_numpy(np.load(\"data/AIF.npy\"))\n",
    "    AIF1 = AIF.view(1, 1, -1) #reshaped for convolution\n",
    "\n",
    "    \n",
    "    #For outputs\n",
    "    #First calculate the parameter Tp\n",
    "    E, Fp ,vp = outputs[:,0], outputs[:,1], outputs[:,2]\n",
    "    Tp=(vp/Fp)*(1-E)\n",
    "    #Calculate the IRF\n",
    "    exptTp= torch.exp(-1*t[:,None]/Tp[None,:]) #adding dummy variables so it divides properly\n",
    "    R=exptTp*(1-E) + E\n",
    "    #Calculate the convolution\n",
    "    R = torch.flip(R, (0,)).T #Reshape to fit the the convolution\n",
    "    R = torch.unsqueeze(R, 1)\n",
    "    temp = t[1]*torch.nn.functional.conv1d(AIF1, R, padding = AIF.shape[0]-1).view(batch_size, -1)\n",
    "\n",
    "    F_out = Fp.unsqueeze(-1)*temp[:,0:len(t)] #unsqueeze to match dimensions\n",
    "    \n",
    "    #For targets - copy pasted\n",
    "    E_true, Fp_true ,vp_true = targets[:,0], targets[:,1], targets[:,2]\n",
    "    Tp_true=(vp_true/Fp_true)*(1-E_true)\n",
    "    #Calculate the IRF\n",
    "    exptTp_true= torch.exp(-1*t[:,None]/Tp_true[None,:]) #adding dummy variables so it divides properly\n",
    "\n",
    "    R_true=exptTp_true*(1-E_true) + E_true\n",
    "\n",
    "    #Calculate the convolution\n",
    "    R_true = torch.flip(R_true, (0,)).T #Reshape to fit the the convolution\n",
    "    R_true = torch.unsqueeze(R_true, 1)\n",
    "    temp_true = t[1]*torch.nn.functional.conv1d(AIF1, R_true, padding = AIF.shape[0]-1).view(batch_size, -1)\n",
    "    F_targets = Fp_true.unsqueeze(-1)*temp_true[:,0:len(t)] #unsqueeze to match dimensions\n",
    "    \n",
    "    MSE = torch.sum((F_out - F_targets)**2)/F_out.shape[1]\n",
    "    \n",
    "    F_targets.register_hook(lambda x: print('F_targets', x, '\\n'))\n",
    "    MSE.register_hook(lambda x: print('MSE', x, '\\n'))\n",
    "\n",
    "\n",
    "    return MSE\n",
    "\n",
    "\n",
    "outputs, targets = torch.DoubleTensor([[0.5, 2e-4, 0.5],[0.4, 2e-5, 0.3]]), torch.DoubleTensor([[0.2, 2.5e-5, 0.5],[0.1, 6e-5, 0.3]])\n",
    "outputs.requires_grad = True\n",
    "targets.requires_grad = True\n",
    "\n",
    "loss = loss_fn_batch_test1(outputs, targets)\n",
    "loss.backward()\n",
    "print(loss.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6ce81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
